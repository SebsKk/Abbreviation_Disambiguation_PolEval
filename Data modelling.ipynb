{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaczm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import MT5ForConditionalGeneration\n",
    "import pandas as pd \n",
    "import transformers\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained('google/mt5-base')\n",
    "# Define your training loop, loss function, optimizer, etc., for fine-tuning\n",
    "\n",
    "training_df = pd.read_csv('C:/Users/kaczm/OneDrive/Pulpit/Abbr_env/training_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MT5Tokenizer\n",
    "import json\n",
    "\n",
    "def create_expected_df(data_path):\n",
    "\n",
    "    df = pd.read_csv(data_path, sep='\\t', header=None, names=['expanded_abbreviation', 'base_abbreviation'])\n",
    "\n",
    "    return df\n",
    "   \n",
    "\n",
    "def create_in_df(data_path_in, data_path_out):\n",
    "\n",
    "    df = pd.read_csv(data_path_in, sep='\\t', header=None, names=['abbreviation', 'context'])\n",
    "\n",
    "    out_df = create_expected_df(data_path_out)\n",
    "\n",
    "    df = pd.merge(df, out_df, left_index=True, right_index=True)\n",
    "\n",
    "    tokenizer = MT5Tokenizer.from_pretrained('google/mt5-large')  \n",
    "\n",
    "    def tokenize_data(context, expanded_abbreviation):\n",
    "        tokenized_input = tokenizer.encode(context, return_tensors='pt', max_length=512, truncation=True)\n",
    "        tokenized_target = tokenizer.encode(expanded_abbreviation, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "        # Convert tensors to lists and then to JSON strings\n",
    "        json_input = json.dumps(tokenized_input.tolist()[0])  # [0] to remove batch dimension\n",
    "        json_target = json.dumps(tokenized_target.tolist()[0])\n",
    "        return json_input, json_target\n",
    "\n",
    "     \n",
    "    df['tokenized_input'], df['tokenized_target'] = zip(*df.apply(lambda x: tokenize_data(x['context'], x['expanded_abbreviation']), axis=1))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MT5Tokenizer.from_pretrained('google/mt5-large')\n",
    "\n",
    "def tokenize_and_update(row):\n",
    "    \n",
    "    tokenized_input = tokenizer.encode(row['context'], return_tensors='pt', max_length=512, truncation=True)\n",
    "    tokenized_target = tokenizer.encode(row['expanded_abbreviation'], return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "    # Convert tensors to lists and then to JSON strings\n",
    "    row['tokenized_input'] = json.dumps(tokenized_input.tolist()[0])  # [0] to remove batch dimension\n",
    "    row['tokenized_target'] = json.dumps(tokenized_target.tolist()[0])\n",
    "    return row\n",
    "\n",
    "# Apply the function to each row\n",
    "training_df = training_df.apply(tokenize_and_update, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import ast\n",
    "import torch\n",
    "\n",
    "\n",
    "class AbbreviationDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataframe.iloc[idx]\n",
    "        input_ids = torch.tensor(json.loads(item['tokenized_input']))\n",
    "        labels = torch.tensor(json.loads(item['tokenized_target']))\n",
    "        return {'input_ids': input_ids, 'labels': labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece\n",
    "\n",
    "val_dataset = create_in_df('C:/Users/kaczm/OneDrive/Pulpit/Abbr_env/in_validation.tsv', 'C:/Users/kaczm/OneDrive/Pulpit/Abbr_env/expected_validation.tsv')\n",
    "\n",
    "test_dataset_original = pd.concat([\n",
    "    create_in_df(\"C:/Users/kaczm/OneDrive/Pulpit/Abbr_env/in_test_a.tsv\", \"C:/Users/kaczm/OneDrive/Pulpit/Abbr_env/expected_test_a.tsv\"),\n",
    "    create_in_df(\"C:/Users/kaczm/OneDrive/Pulpit/Abbr_env/in_test_b.tsv\", \"C:/Users/kaczm/OneDrive/Pulpit/Abbr_env/expected_test_b.tsv\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AbbreviationDataset(training_df)\n",
    "val_dataset = AbbreviationDataset(val_dataset)  \n",
    "test_dataset = AbbreviationDataset(test_dataset_original)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[259, 17093, 18740, 259, 107669, 259, 110416, 259, 266, 259, 144390, 259, 268, 65348, 276, 259, 263, 210001, 268, 104990, 3407, 78718, 650, 259, 268, 485, 5417, 14068, 160987, 1042, 55114, 669, 3105, 3598, 400, 2946, 265, 716, 455, 4430, 259, 202425, 59353, 11525, 9394, 259, 266, 259, 337, 89793, 25177, 38260, 38893, 414, 10207, 662, 259, 72512, 262, 1]\n",
      "[259, 197642, 1]\n"
     ]
    }
   ],
   "source": [
    "print(training_df['tokenized_input'].iloc[0])\n",
    "print(training_df['tokenized_target'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Separate the input_ids and labels\n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "\n",
    "    # Pad the sequences to the maximum length in the batch\n",
    "    input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    labels_padded = pad_sequence(labels, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    return {'input_ids': input_ids_padded, 'labels': labels_padded}\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaczm\\.virtualenvs\\Abbr_env-FC8IvZ7o\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training loss: 29.221603108875787\n",
      "Epoch 1/10 - Validation loss: 22.359008026123046\n",
      "Epoch 2/10 - Training loss: 19.09498912896683\n",
      "Epoch 2/10 - Validation loss: 13.458402919769288\n",
      "Epoch 3/10 - Training loss: 11.145802764750238\n",
      "Epoch 3/10 - Validation loss: 6.284316539764404\n",
      "Epoch 4/10 - Training loss: 6.357855243469352\n",
      "Epoch 4/10 - Validation loss: 3.951567530632019\n",
      "Epoch 5/10 - Training loss: 4.854924235770952\n",
      "Epoch 5/10 - Validation loss: 3.319741439819336\n",
      "Epoch 6/10 - Training loss: 4.221307989376695\n",
      "Epoch 6/10 - Validation loss: 3.0302732467651365\n",
      "Epoch 7/10 - Training loss: 3.870023554830409\n",
      "Epoch 7/10 - Validation loss: 2.8029598951339723\n",
      "Epoch 8/10 - Training loss: 3.7244830291662643\n",
      "Epoch 8/10 - Validation loss: 2.677043151855469\n",
      "Epoch 9/10 - Training loss: 3.549687568821124\n",
      "Epoch 9/10 - Validation loss: 2.6325679779052735\n",
      "Epoch 10/10 - Training loss: 3.583093061375974\n",
      "Epoch 10/10 - Validation loss: 2.591477608680725\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "warmup_steps = int(total_steps * 0.1)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "# Variables for tracking progress\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "early_stopping_limit = 3  # Stop if no improvement after 3 consecutive epochs\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Training loss: {avg_train_loss}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Validation loss: {avg_val_loss}\")\n",
    "\n",
    "    # Save the best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        model.save_pretrained('path_to_save_best_model')\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter >= early_stopping_limit:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "# Load the best model for further use or inference\n",
    "model = MT5ForConditionalGeneration.from_pretrained('path_to_save_best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MT5ForConditionalGeneration(\n",
       "  (shared): Embedding(250112, 768)\n",
       "  (encoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=250112, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'C:/Users/kaczm/OneDrive/Pulpit/Abbr_env/path_to_save_best_model'\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_path)\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MT5ForConditionalGeneration(\n",
       "  (shared): Embedding(250112, 768)\n",
       "  (encoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=250112, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaczm\\.virtualenvs\\Abbr_env-FC8IvZ7o\\Lib\\site-packages\\transformers\\generation\\utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of expanded abbreviations (Af): 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to track the number of correct predictions and total predictions\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# Evaluate the model\n",
    "for batch in test_loader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(input_ids=input_ids, attention_mask=input_ids.ne(0))\n",
    "\n",
    "    # Decode outputs and labels to text\n",
    "    output_texts = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "    label_texts = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n",
    "\n",
    "    # Compare output_texts with label_texts and calculate accuracy\n",
    "    for output_text, label_text in zip(output_texts, label_texts):\n",
    "        if output_text == label_text:\n",
    "            correct_predictions += 1\n",
    "        total_predictions += 1\n",
    "\n",
    "# Calculate and print the overall accuracy\n",
    "accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "print(f'Accuracy of expanded abbreviations (Af): {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaczm\\.virtualenvs\\Abbr_env-FC8IvZ7o\\Lib\\site-packages\\transformers\\generation\\utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions and decode them to text\n",
    "predicted_expansions = []\n",
    "for batch in test_loader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(input_ids=input_ids, attention_mask=input_ids.ne(0))\n",
    "\n",
    "    predicted_batch = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "    predicted_expansions.extend(predicted_batch)\n",
    "\n",
    "# Add the predictions to the original test DataFrame\n",
    "test_dataset_original['predicted_expanded_abbreviation'] = predicted_expansions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaczm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "C:\\Users\\kaczm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaczm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.2966515123844147\n",
      "Test Loss after Epoch 1: 0.14322816643591482\n",
      "Epoch 2/5, Loss: 0.16756057739257812\n",
      "Test Loss after Epoch 2: 0.098079183089165\n",
      "Epoch 3/5, Loss: 0.4180033206939697\n",
      "Test Loss after Epoch 3: 0.07183858133001511\n",
      "Epoch 4/5, Loss: 0.08358603715896606\n",
      "Test Loss after Epoch 4: 0.058316460531281464\n",
      "Epoch 5/5, Loss: 0.03675549104809761\n",
      "Test Loss after Epoch 5: 0.05246976653271605\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# Function to move batches to a device\n",
    "def to_device(batch, device):\n",
    "    return {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "# Load and preprocess data\n",
    "def preprocess_data(df):\n",
    "    df['input_text'] = \"expand abbreviation: \" + df['abbreviation'] + \" in context: \" + df['context']\n",
    "    df['target_text'] = df['expanded_abbreviation']  \n",
    "    return df\n",
    "\n",
    "# Load the CSV files\n",
    "training_df = pd.read_csv('C:/Users/kaczm/OneDrive/Pulpit/Abbr_env_v2/training_df.csv')\n",
    "test_df = pd.read_csv('C:/Users/kaczm/OneDrive/Pulpit/Abbr_env_v2/test_df.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "training_df = preprocess_data(training_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "\n",
    "\n",
    "# Define a custom dataset\n",
    "class AbbreviationDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.inputs = data['input_text']\n",
    "        self.targets = data['target_text']\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_text = self.inputs[idx]\n",
    "        target_text = self.targets[idx]\n",
    "\n",
    "        # Tokenize input and target texts\n",
    "        input_tokens = self.tokenizer.encode_plus(input_text, max_length=self.max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
    "        target_tokens = self.tokenizer.encode_plus(target_text, max_length=self.max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
    "\n",
    "        # Combine input and target tokens into one dictionary\n",
    "        return {**input_tokens, 'labels': target_tokens['input_ids']}\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")  \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA being used') \n",
    "model.to(device)\n",
    "\n",
    "# Create Dataset and DataLoader for training and test data\n",
    "train_dataset = AbbreviationDataset(tokenizer, training_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "test_dataset = AbbreviationDataset(tokenizer, test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        # Move batch to the appropriate device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Unpack the input and labels from the batch\n",
    "        input_ids = batch['input_ids'].squeeze(1)\n",
    "        labels = batch['labels'].squeeze(1)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    # Evaluate on test data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for batch in test_loader:\n",
    "            # Move batch to the appropriate device\n",
    "            batch = to_device(batch, device)\n",
    "\n",
    "            # Unpack the input and labels from the batch\n",
    "            input_ids = batch['input_ids'].squeeze(1)\n",
    "            labels = batch['labels'].squeeze(1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, labels=labels)\n",
    "            total_loss += outputs.loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(test_loader)\n",
    "        print(f\"Test Loss after Epoch {epoch+1}: {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to final_model\n"
     ]
    }
   ],
   "source": [
    "model_save_path = 'final_model'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaczm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model (if not already in memory)\n",
    "model.load_state_dict(torch.load('final_model'))\n",
    "model.eval()\n",
    "\n",
    "# Variables to store predictions and actual values\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "# Iterate over test data\n",
    "for batch in test_loader:\n",
    "    # Move batch to the appropriate device\n",
    "    batch = to_device(batch, device)\n",
    "\n",
    "    # Forward pass without gradient calculation\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids'].squeeze(1)\n",
    "        labels = batch['labels'].squeeze(1)\n",
    "\n",
    "        outputs = model.generate(input_ids=input_ids)\n",
    "        \n",
    "        # Convert outputs and labels to lists for evaluation\n",
    "        pred_list = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outputs]\n",
    "        labels_list = [tokenizer.decode(ids, skip_special_tokens=True) for ids in labels]\n",
    "\n",
    "        predictions.extend(pred_list)\n",
    "        actuals.extend(labels_list)\n",
    "\n",
    "# Now 'predictions' and 'actuals' contain the model's predictions and the true labels, respectively.\n",
    "# You can use these lists to calculate accuracy or other metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<extra_id_0> Guillaume.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> s. 16). s. 16',\n",
       " '<extra_id_0> Marius Lindvik - 129',\n",
       " '<extra_id_0> służy pielęgnacji i ',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> o możliwości PO i PO',\n",
       " '<extra_id_0>. ) o. o. o.',\n",
       " '<extra_id_0> ) o.o.',\n",
       " '<extra_id_0> drogi o krawędzi drogi o',\n",
       " '<extra_id_0> - g. g. g. g. g.',\n",
       " '<extra_id_0> ul.. <extra_id_14> ul..',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> utrzymania.',\n",
       " '<extra_id_0> o nazwiska o nazwisku o nazwisku o ',\n",
       " '<extra_id_0> (in context: )',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> zmian. s.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> - undefined:',\n",
       " '<extra_id_0>?',\n",
       " '<extra_id_0> o. o. o.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> i.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> WZ -',\n",
       " '<extra_id_0> usługi usługi usługi usługi ',\n",
       " '<extra_id_0> znaczenia znaczenia obecności serii.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o nazwisku o nazwisku o nazwisku o ',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> u. u. u. u. u. u.',\n",
       " '<extra_id_0> - n.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o świadczenia pracy nie powoduje naruszenia art. 151k.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> nauczyciela była nauczycielem. <extra_id_8> nauczyciela była ',\n",
       " '<extra_id_0> śpiewa p.',\n",
       " '<extra_id_0> i w.e.ow',\n",
       " '<extra_id_0> zginęło ciała ciała',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> >',\n",
       " '<extra_id_0>) (s.)',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> - s. s.',\n",
       " '<extra_id_0> a a <extra_id_12> a',\n",
       " '<extra_id_0> g. g.',\n",
       " '<extra_id_0> pliku pliku pliku pliku pliku pliku pliku pliku pliku',\n",
       " '<extra_id_0> - miasto -',\n",
       " '<extra_id_0> o. o. o. o.',\n",
       " '<extra_id_0> i ks. i ks. i ks. i ',\n",
       " '<extra_id_0> polskich nagrań pełnych części części części części części',\n",
       " '<extra_id_0> s. in',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> i nazwiska i',\n",
       " '<extra_id_0> Zombie. Privates jest dziełem Zombie -',\n",
       " '<extra_id_0> s. in context:',\n",
       " '<extra_id_0> : margin: s.',\n",
       " '<extra_id_0> i <mask>.',\n",
       " '<extra_id_0> / <extra_id_14> ',\n",
       " '<extra_id_0> XIX- XIX XIX -',\n",
       " '<extra_id_0> n.',\n",
       " '<extra_id_0>.',\n",
       " \"<extra_id_0> 'p. 'p. '.\",\n",
       " '<extra_id_0> synonym: w.',\n",
       " '<extra_id_0> o. o. o.',\n",
       " '<extra_id_0>  <extra_id_1> i.',\n",
       " '<extra_id_0> obywatelskiej. <extra_id_34> obywatelskiej obywatelskiej obywatelskiej',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o. <extra_id_10> o.',\n",
       " '<extra_id_0> otrzymają dodatkowe pieniądze.',\n",
       " '<extra_id_0> - undefined >',\n",
       " '<extra_id_0> a a <extra_id_10> a a',\n",
       " '<extra_id_0> o prokuraturze -',\n",
       " '<extra_id_0> obywatelskiej -',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> a g. a',\n",
       " '<extra_id_0> )',\n",
       " '<extra_id_0> )',\n",
       " '<extra_id_0> o łez.',\n",
       " '<extra_id_0> ) a.',\n",
       " '<extra_id_0> o 35% nie utrzymała o 35% części. /',\n",
       " '<extra_id_0> o służy układem u usługi',\n",
       " '<extra_id_0> )',\n",
       " '<extra_id_0>1 (<mask> 1)',\n",
       " '<extra_id_0> r.',\n",
       " '<extra_id_0> oznacza o t.',\n",
       " '<extra_id_0> oznacza o t.',\n",
       " '<extra_id_0> usługi usługi usługi usługi usługi usługi',\n",
       " '<extra_id_0> - Temat Temat Temat Temat Temat Temat Temat Temat',\n",
       " '<extra_id_0> i nazwiska. <extra_id_35> nazwiska.',\n",
       " '<extra_id_0>: w. w. cyfra.',\n",
       " '<extra_id_0> i nazwisk. <extra_id_10> i nazwiska.',\n",
       " '<extra_id_0> o nazwą.',\n",
       " '<extra_id_0> s. s. s. s. s. s.',\n",
       " '<extra_id_0> o. o.',\n",
       " '<extra_id_0> i expire expire i  <extra_id_51> i zmiany i ',\n",
       " '<extra_id_0> p. Zaborskiej.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> <extra_id_1> -',\n",
       " '<extra_id_0> ciała ciała ciała ciała ciała',\n",
       " '<extra_id_0>) ))))))))))))))))',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> - ',\n",
       " '<extra_id_0> o stanowiącej prawo. <extra_id_27>',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0> /',\n",
       " '<extra_id_0> oznacza o o o o o o o ',\n",
       " '<extra_id_0> o polityka polityka',\n",
       " '<extra_id_0> i.',\n",
       " '<extra_id_0> Tenisa <extra_id_14> Tenisa -',\n",
       " '<extra_id_0> ) ))',\n",
       " '<extra_id_0> - zobacz szczegóły',\n",
       " \"<extra_id_0> i nie lokował jego pieniędzy. 'Nie lokował jego pien\",\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> i symbole i symbole symbole symbole symbole symbole symbole',\n",
       " '<extra_id_0> oznacza o kierunkowym kierunkowym kierunkiem o kierun',\n",
       " '<extra_id_0> o polityka. <extra_id_14> polityka',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> służą pełne i zdrowej.cych',\n",
       " \"<extra_id_0> '.\",\n",
       " '<extra_id_0> uzyskała 82. w.',\n",
       " '<extra_id_0> o. o. o. o. o.',\n",
       " '<extra_id_0> Niemcy -',\n",
       " '<extra_id_0>.)',\n",
       " '<extra_id_0> pożyczki w zależności od wartości usług pożyczkowych.ch <extra_id_10>',\n",
       " '<extra_id_0> i.',\n",
       " '<extra_id_0> - g.',\n",
       " '<extra_id_0> o nazwiska. <extra_id_8> nazwiska nazwiska nazwiska',\n",
       " '<extra_id_0>. ) o.',\n",
       " '<extra_id_0> o wyborach.',\n",
       " '<extra_id_0> około 6300 m',\n",
       " '<extra_id_0> dzielę. <extra_id_34> dzielę dzielę dzielę dzielę ',\n",
       " '<extra_id_0>: o.',\n",
       " '<extra_id_0>. ). ) <extra_id_10>',\n",
       " '<extra_id_0> - zobacz więcej o',\n",
       " '<extra_id_0> multiplayer) multiplayer))',\n",
       " '<extra_id_0> a jest równe części części części',\n",
       " '<extra_id_0> o. o. o. o. o.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> - tłumaczy tłumacza',\n",
       " '<extra_id_0> ) n.',\n",
       " '<extra_id_0> uzyskał 21,16 m.',\n",
       " '<extra_id_0> (s. 16)',\n",
       " '<extra_id_0> (s.17)',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> ) -',\n",
       " '<extra_id_0> firmy... <extra_id_8>.',\n",
       " '<extra_id_0> usługi. <extra_id_10> usługi usługi',\n",
       " '<extra_id_0> otrzymał święcenia kapłańskie -',\n",
       " '<extra_id_0> - n. n. n. n.',\n",
       " '<extra_id_0> s s s s s s',\n",
       " '<extra_id_0> - a <extra_id_10> ',\n",
       " '<extra_id_0> o artykule. <extra_id_27>',\n",
       " '<extra_id_0>. ). []. <extra_id_8>.',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> - polski polityka',\n",
       " '<extra_id_0> -.cw',\n",
       " '<extra_id_0> i rocznicę obelisku. i synonymous',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> r. r. o <extra_id_14> o',\n",
       " '<extra_id_0> n. 18',\n",
       " '<extra_id_0> s.',\n",
       " '<extra_id_0> - undefined >',\n",
       " '<extra_id_0>?, ',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> jego żony.cych',\n",
       " '<extra_id_0> expand abbreviation: p. Expand : p. Expand : p',\n",
       " '<extra_id_0> - m.',\n",
       " '<extra_id_0> Anonimowy',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> 3900 r. r. r. r. r. ',\n",
       " '<extra_id_0> - exports exports exports exports exports exports exports exports',\n",
       " '<extra_id_0> i.',\n",
       " '<extra_id_0>. -',\n",
       " '<extra_id_0> o. o. o.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> >',\n",
       " '<extra_id_0> r.',\n",
       " '<extra_id_0> utworzony przez Hajdarowicza.',\n",
       " '<extra_id_0> około. <extra_id_10> około.',\n",
       " '<extra_id_0>) s. 18',\n",
       " '<extra_id_0> ś.',\n",
       " '<extra_id_0> o SKW i SWW?cych o SWW ',\n",
       " '<extra_id_0> - tłumaczył',\n",
       " '<extra_id_0> głosu głosu;',\n",
       " '<extra_id_0> oznacza tzw. ',\n",
       " '<extra_id_0> - Pin. Expand Expand. Expand',\n",
       " '<extra_id_0> - w.in <extra_id_10> -',\n",
       " '<extra_id_0> g. 3:3 g.',\n",
       " '<extra_id_0> g. 3:3 g.',\n",
       " '<extra_id_0> r./',\n",
       " '<extra_id_0> biskupie Wiktorze. <extra_id_9> ',\n",
       " '<extra_id_0> )',\n",
       " '<extra_id_0> s. s. s. s. s. s.',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> oznacza o polityka',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0> o Polskiej tradycji.ch <extra_id_14> ',\n",
       " '<extra_id_0> -. <extra_id_8> -',\n",
       " '<extra_id_0> sąd.',\n",
       " '<extra_id_0> nazwiska nazwiska nazwiska nazwiska nazwiska nazwiska',\n",
       " '<extra_id_0> - uzg. n.',\n",
       " '<extra_id_0>. ).cych',\n",
       " '<extra_id_0> i.',\n",
       " '<extra_id_0> s. s. s. s. s. s.',\n",
       " '<extra_id_0> gmina.aловна.',\n",
       " '<extra_id_0> służącej ośrodku usługi ochrony mienia.cych',\n",
       " '<extra_id_0> i.',\n",
       " '<extra_id_0> serii o serii o serii o dziech.ch>',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> - nauka jazdy',\n",
       " '<extra_id_0> stanowiska szefa szefa',\n",
       " '<extra_id_0> o o o o o o o o o',\n",
       " '<extra_id_0> - polski język polski polski',\n",
       " '<extra_id_0> o. o. o. o.',\n",
       " '<extra_id_0> Szkoły Podstawowej <mask> Obrońców Szkoły Eduka',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> i',\n",
       " '<extra_id_0> - cyfra cyfra cyfra',\n",
       " '<extra_id_0> s. expand abbreviation: <extra_id_10> s. expand s. expand ',\n",
       " '<extra_id_0>) 15.50 (p.',\n",
       " '<extra_id_0> - undefined >',\n",
       " '<extra_id_0> i kościoła o XIV stopnia i XIV stopni',\n",
       " '<extra_id_0>  <extra_id_1> -',\n",
       " '<extra_id_0> wersja Alfa 2.<mask>',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> - ) -. ) )',\n",
       " '<extra_id_0> - <mask>',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> Kobiety. <extra_id_12>',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> - s.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o. o. o. o.',\n",
       " '<extra_id_0> Marek Marek. Marek ',\n",
       " '<extra_id_0> oświetlenia.',\n",
       " '<extra_id_0> l. expand l. expand l.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> i znaczenie.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> - nauka o artykule',\n",
       " '<extra_id_0>. części.',\n",
       " '<extra_id_0> - synonymous:',\n",
       " '<extra_id_0> i',\n",
       " '<extra_id_0> czasowo wchodzi w życie nowa taryfa',\n",
       " '<extra_id_0> - 128 m.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> -. Liga. -',\n",
       " '<extra_id_0>:',\n",
       " '<extra_id_0> - a n.p.a <extra_id_14> ',\n",
       " '<extra_id_0> a.',\n",
       " '<extra_id_0> - miasto -',\n",
       " '<extra_id_0> szybko pędzić po nim -',\n",
       " '<extra_id_0> i',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> Galeria Faras -',\n",
       " '<extra_id_0> s. s. s.',\n",
       " '<extra_id_0> - więcej o zmianach w prawie drogowym? <extra_id_46>',\n",
       " '<extra_id_0>:',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> lądowania na 136 <mask> lądowania na 136 <mask> ląd',\n",
       " '<extra_id_0> lądowania na 136 <mask> lądowania na 136 <mask> ląd',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0> - polski alfabet:',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> -.',\n",
       " '<extra_id_0> o nazwach. <extra_id_10> nazwą',\n",
       " '<extra_id_0> p.',\n",
       " '<extra_id_0> – s. 16). s. 16). s. 16). s',\n",
       " '<extra_id_0> obywatelskiego -',\n",
       " '<extra_id_0> o. o. o. o. o.',\n",
       " '<extra_id_0> (n. 16',\n",
       " '<extra_id_0> służbowe.',\n",
       " '<extra_id_0> sęp. <extra_id_10> sęzyk.',\n",
       " '<extra_id_0> o 37',\n",
       " '<extra_id_0> - usługa',\n",
       " '<extra_id_0> o. o. o. o.',\n",
       " '<extra_id_0> nazwiska Abrahama.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o s s s s s',\n",
       " '<extra_id_0> -.. <extra_id_8>.',\n",
       " '<extra_id_0> s. expand abbreviation: s. expand s. expand',\n",
       " '<extra_id_0> wskazane jest wskazanie wskazań. <extra_id_8> wskazane',\n",
       " '<extra_id_0> - cyfra : <extra_id_10> cyfra  <extra_id_11> cyfra',\n",
       " '<extra_id_0> nazw nazw nazw nazw nazw nazw nazw nazw nazw',\n",
       " '<extra_id_0>) (s.)',\n",
       " '<extra_id_0> - LKS Dąb Barciński - LKS Dąb',\n",
       " '<extra_id_0> – 1946 NIDA (<mask> 16)',\n",
       " '<extra_id_0> i związku. <extra_id_8> i związku.',\n",
       " '<extra_id_0> polski -',\n",
       " '<extra_id_0> g.',\n",
       " '<extra_id_0> polityka amerykańska -',\n",
       " '<extra_id_0> - undefined undefined undefined undefined undefined undefined undefined',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> - polska wersja -',\n",
       " '<extra_id_0> Gdańska  <extra_id_18> miasto miasto miasto miasto miasto miasto ',\n",
       " '<extra_id_0> o zmianie ustawy o zmianie ustawy',\n",
       " '<extra_id_0> i zamordowanie. <extra_id_8> i',\n",
       " '<extra_id_0> np.',\n",
       " '<extra_id_0> - LKS Jawiszowice (',\n",
       " '<extra_id_0> - a a',\n",
       " '<extra_id_0> wskazuje prawo.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> o obowiązku.cych ',\n",
       " '<extra_id_0> n. 17',\n",
       " '<extra_id_0> )',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> - Startowa - Starta',\n",
       " '<extra_id_0> wskazał p.',\n",
       " '<extra_id_0> wiatru.',\n",
       " '<extra_id_0> owies konsumpcyjny nie był zgłoszony nie owies',\n",
       " '<extra_id_0> 1,6 benzynowego 1,6 benzynowego 1,6 benzynowego 1,6 benzynowego 1,6',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> ). <extra_id_49> i symbole kwiaty i kwiaty. ',\n",
       " '<extra_id_0> (s. 16)',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> - p. s.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> o. o. o.',\n",
       " '<extra_id_0> o. in',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> (s. 16)',\n",
       " '<extra_id_0> - w.',\n",
       " '<extra_id_0> stanowią emerytury.',\n",
       " '<extra_id_0> r./',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o. o. o. o. o.',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> - uchwalę -',\n",
       " '<extra_id_0> nazwiska.',\n",
       " '<extra_id_0>.. <extra_id_8>..',\n",
       " '<extra_id_0> Markus Eisenbichlera',\n",
       " '<extra_id_0> Markus Eisenbichlera',\n",
       " '<extra_id_0> służbę unijnej -',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> i. <extra_id_8> i.',\n",
       " '<extra_id_0> u.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> architektura.',\n",
       " '<extra_id_0> – n. 11',\n",
       " '<extra_id_0> o polski i <extra_id_14>',\n",
       " '<extra_id_0> o zachodu wzmagający się o zachodu',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> - 102 m. <extra_id_10> - 102',\n",
       " '<extra_id_0> o',\n",
       " '<extra_id_0> n.',\n",
       " '<extra_id_0>. Flash Info, <mask>',\n",
       " '<extra_id_0> - ś.',\n",
       " '<extra_id_0> - ś.',\n",
       " '<extra_id_0> nazw: w.',\n",
       " '<extra_id_0> separator. in context:',\n",
       " '<extra_id_0> służą mieszaniną mieszanką.dź. ć.zyk',\n",
       " '<extra_id_0>. ). <extra_id_49> : ) ) ) ) )',\n",
       " '<extra_id_0> około około',\n",
       " '<extra_id_0> a polityka',\n",
       " '<extra_id_0> symbole symboliczne Symboly Symbola',\n",
       " '<extra_id_0> -.. <extra_id_8>.',\n",
       " '<extra_id_0> -. <extra_id_10> /.',\n",
       " '<extra_id_0> miasto miasto miasto miasto miasto miasto miasto miasto miasto',\n",
       " '<extra_id_0> o. o. o.',\n",
       " '<extra_id_0> g.',\n",
       " \"<extra_id_0> '\",\n",
       " '<extra_id_0> - czym stanowi karę -',\n",
       " '<extra_id_0>. o. o.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> pożegnało wypadek.uszcz. <extra_id_10>',\n",
       " '<extra_id_0> a.',\n",
       " '<extra_id_0> i wszystko.',\n",
       " '<extra_id_0> - rmf24.pl',\n",
       " '<extra_id_0> -. <extra_id_10> -. -. -',\n",
       " '<extra_id_0> ciała.ilicitud.',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> s.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> multiplayer.',\n",
       " '<extra_id_0> GIS GIS GIS GIS GIS GIS GIS GIS',\n",
       " '<extra_id_0> polskim politykom.',\n",
       " '<extra_id_0> o. o. o.',\n",
       " '<extra_id_0> gwiazd, gwiazd,',\n",
       " '<extra_id_0> - polski p. polski',\n",
       " '<extra_id_0> czasowe.',\n",
       " '<extra_id_0> g. 16',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0> ks. ks. ks. ks. ks. ks.',\n",
       " '<extra_id_0> a do <mask>',\n",
       " '<extra_id_0> w. w. w. context:',\n",
       " '<extra_id_0> o prędkości',\n",
       " '<extra_id_0> została poszkodowana. <extra_id_10>  <extra_id_11> ',\n",
       " '<extra_id_0> i',\n",
       " '<extra_id_0> - wszystkie - części części części',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> s. s. s.',\n",
       " '<extra_id_0> -.cych',\n",
       " '<extra_id_0>. ). <extra_id_49> i trasy trasy - trasy - ',\n",
       " '<extra_id_0> - - - - - - - - -',\n",
       " \"<extra_id_0> o. '.\",\n",
       " '<extra_id_0> > n.',\n",
       " '<extra_id_0> o. s. <extra_id_27> s',\n",
       " '<extra_id_0> zwolnienia zwolnienia zwolnienia zwolnienia zwolnienia',\n",
       " '<extra_id_0> o o o o o o o o o',\n",
       " '<extra_id_0> - nie da rady - nie da rady',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> - p. p. : s. <extra_id_8> :',\n",
       " '<extra_id_0> - ',\n",
       " '<extra_id_0> -.. <extra_id_34>.',\n",
       " '<extra_id_0> - 133 m.',\n",
       " '<extra_id_0>?  <extra_id_1>?',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> służącej zmiana czasowe. []',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0> Francesca <mask>',\n",
       " '<extra_id_0> dostaną w podarunku.',\n",
       " '<extra_id_0> u u u u u u u u u',\n",
       " '<extra_id_0> - n. 17',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> zyskuje zysku ',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> - undefined >',\n",
       " '<extra_id_0> - undefined >',\n",
       " '<extra_id_0> o o o o o o o o o',\n",
       " '<extra_id_0>?',\n",
       " '<extra_id_0> winy.',\n",
       " \"<extra_id_0> '\",\n",
       " '<extra_id_0> - m.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> - s. s. s. s. s. ',\n",
       " '<extra_id_0> i polityka',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> i skutecznie skutecznie skutecznie skutecznie skutecznie.',\n",
       " '<extra_id_0> otrzymywały coraz więcej.',\n",
       " '<extra_id_0> o wiatru',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> został zatrzymany -',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> - a służę -',\n",
       " '<extra_id_0> - Korona II - Korona II ',\n",
       " '<extra_id_0> oznacza 50 km/h. <extra_id_34>',\n",
       " '<extra_id_0> a znaczeniu usługi usług usług usług usług usług',\n",
       " '<extra_id_0> oznacza o',\n",
       " '<extra_id_0> służą klasy pierwszej i',\n",
       " '<extra_id_0> Departamentu Gospodarstwa',\n",
       " '<extra_id_0> osiedlowych. <extra_id_34> osiedla -',\n",
       " '<extra_id_0> i nazwiska',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0>\". -',\n",
       " '<extra_id_0> stanowi szef CBA Dariusz Rosati. <extra_id_8> ',\n",
       " '<extra_id_0> wschodnia:',\n",
       " '<extra_id_0> wschodnia:',\n",
       " '<extra_id_0> oznacza znaczenia znaczenia owe owe ',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> - - - - -',\n",
       " '<extra_id_0> r. r.',\n",
       " '<extra_id_0> s. s. s. s. s. s.',\n",
       " '<extra_id_0>. )',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o. in',\n",
       " '<extra_id_0> (s. 16)',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0> - t. t. t. t.',\n",
       " '<extra_id_0> polityka',\n",
       " '<extra_id_0> rezerwacji rezerwacji rezerwacji rezerwacji rezerwacji rezerwacji',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> s.',\n",
       " '<extra_id_0> widokowymi atrakcjami widokowymi.cych',\n",
       " '<extra_id_0> )',\n",
       " '<extra_id_0> koziego.',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.)) o.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> ). ) <extra_id_34> :.)',\n",
       " '<extra_id_0> znaczenia znaczenia',\n",
       " '<extra_id_0> nazwiska.',\n",
       " '<extra_id_0> o pomoc prawną.',\n",
       " '<extra_id_0> angielskiego.',\n",
       " '<extra_id_0> - muzyka muzyka muzyka muzyka muzyka',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0>? a',\n",
       " '<extra_id_0> ferrari f12td.',\n",
       " '<extra_id_0> i nazwiska Chr. i <extra_id_14> ',\n",
       " '<extra_id_0> dent.',\n",
       " '<extra_id_0> o. in context:',\n",
       " '<extra_id_0> i usługi i',\n",
       " '<extra_id_0> -. <extra_id_10> -',\n",
       " '<extra_id_0> PCC. zmiana umowy o PCC',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>. ). <extra_id_8>.',\n",
       " '<extra_id_0>.)).)',\n",
       " '<extra_id_0> np.',\n",
       " '<extra_id_0> o wskazał o wskazaniem o wskazaniem o',\n",
       " '<extra_id_0> np.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> - żadne tramwaje.',\n",
       " '<extra_id_0> i służyła służbowi i służę służę.',\n",
       " '<extra_id_0> o nazwiska.alicitud ',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> polski.',\n",
       " '<extra_id_0> - nauka o tańcu o tańcu o',\n",
       " '<extra_id_0> o rosyjskiej,',\n",
       " '<extra_id_0> nazwiska:',\n",
       " '<extra_id_0> o jego powrocie powiedział w sobotę',\n",
       " '<extra_id_0> - s.',\n",
       " '<extra_id_0> Kraków,',\n",
       " '<extra_id_0> - polski klimatyzacja',\n",
       " \"<extra_id_0> '.\",\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> głosi.ch',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> i g. g. g.',\n",
       " \"<extra_id_0> '\",\n",
       " '<extra_id_0> - nie',\n",
       " '<extra_id_0> l. l. l. l.',\n",
       " '<extra_id_0> -. <extra_id_8> - nie - nie',\n",
       " \"<extra_id_0> '\",\n",
       " '<extra_id_0> o. o. o.',\n",
       " '<extra_id_0> wskazane: służy bezpieczeństwa kierowcy.cych',\n",
       " '<extra_id_0> śp. adm. śp.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o. in context:',\n",
       " '<extra_id_0> udekorowano <mask>',\n",
       " '<extra_id_0> oznacza o części części.zyk',\n",
       " '<extra_id_0> - g.',\n",
       " '<extra_id_0> - polska tradycja polska tradycja',\n",
       " '<extra_id_0> - Temat:',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o nazwą o',\n",
       " '<extra_id_0> w. w. w. w. w. w.',\n",
       " '<extra_id_0> i słaby,',\n",
       " '<extra_id_0> i słaby,',\n",
       " '<extra_id_0> > <mask> <mask> <mask>',\n",
       " '<extra_id_0> oznacza spada prędkość.',\n",
       " '<extra_id_0> płatności była więc więc? <extra_id_10> ',\n",
       " '<extra_id_0> - o  <extra_id_14> ',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> r. r. r.',\n",
       " '<extra_id_0> - sobota sobota sobota sobotasobot',\n",
       " '<extra_id_0> o. Alta',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>?',\n",
       " '<extra_id_0>. ) >',\n",
       " '<extra_id_0> rzk.',\n",
       " '<extra_id_0> Olympus Mons – Olympus Mons Olympus',\n",
       " '<extra_id_0> > owi.',\n",
       " '<extra_id_0> Kościoła katolickiego nie zakwestionował mienia katolickiego i',\n",
       " '<extra_id_0> p. p. p.',\n",
       " '<extra_id_0> a a',\n",
       " '<extra_id_0> o. <extra_id_10> o.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0>. s. 14.45).',\n",
       " '<extra_id_0> ) służy. służ. służ. <extra_id_7>.',\n",
       " '<extra_id_0> - -',\n",
       " '<extra_id_0> chrześcijański <mask>',\n",
       " '<extra_id_0> a g. 17.',\n",
       " '<extra_id_0> ) o. o.',\n",
       " '<extra_id_0> ćwiczy ćwiczy ćwiczy ćwiczy ć',\n",
       " \"<extra_id_0> o 0,5 p. '\",\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> - polski polski polski polski polski',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> wskazań w. <extra_id_14> ',\n",
       " '<extra_id_0> zmiany czasowe i <extra_id_14> zmiany czasowe ',\n",
       " '<extra_id_0> oprawcy opraw opraw opraw opraw opraw opraw opraw ',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> dzielący dzielę dzielnych dzieleń dzielnych dzieleń',\n",
       " '<extra_id_0> o.cych łapyi.icych <extra_id_4> ',\n",
       " '<extra_id_0> n.',\n",
       " '<extra_id_0> nazw nazw nazw nazw nazw nazw nazw nazw nazw',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> o. <extra_id_14> o.',\n",
       " '<extra_id_0> tłumie.',\n",
       " \"<extra_id_0> linii '. <extra_id_8> linii linii linii linii linii linii\",\n",
       " '<extra_id_0> umierały przez umieranieły przez Abrahama.',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> ciała. ciała. <extra_id_4> ciała.',\n",
       " '<extra_id_0> o spółki prawa handlowego. <extra_id_8> o',\n",
       " '<extra_id_0> Książki Książki Książki Książki',\n",
       " '<extra_id_0> o. <extra_id_27> o. <extra_id_8> o. o. o.',\n",
       " '<extra_id_0> >',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0>. ). <extra_id_52> r. r. r. r. ',\n",
       " '<extra_id_0> granicę 200 m.',\n",
       " '<extra_id_0> nazwałem nazwą.ch.cych',\n",
       " '<extra_id_0> o nazwie Skoda Leasing -',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> : p. expand abbreviation: <extra_id_10>',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0> x.',\n",
       " '<extra_id_0> \"Merinotex\"',\n",
       " '<extra_id_0> i muzyka. <extra_id_8> i',\n",
       " '<extra_id_0> nie o służę sławieńskim.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> Andrzeja.o.licitude',\n",
       " '<extra_id_0> - zobacz więcej:',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> o. <extra_id_10> o.',\n",
       " '<extra_id_0> o 0,75 proc. a',\n",
       " \"<extra_id_0> '\",\n",
       " '<extra_id_0> i ożywionym. ożywi',\n",
       " '<extra_id_0> )',\n",
       " '<extra_id_0> l. l. l. l.',\n",
       " '<extra_id_0> - s. s. s. s. s. ',\n",
       " '<extra_id_0> i',\n",
       " '<extra_id_0> Boeingiem 777 777 777 777 777 777 777 777 777 777 777 777 777 777 777',\n",
       " '<extra_id_0> s. expand ab <extra_id_10>: s. expand s. expand s.',\n",
       " '<extra_id_0> ewidencji ewidencji ewidencji ewidencji ewidencji ewidencji',\n",
       " '<extra_id_0> o. Gużyński o.',\n",
       " '<extra_id_0>. –',\n",
       " '<extra_id_0> - służy -',\n",
       " '<extra_id_0> o polityka',\n",
       " '<extra_id_0> - Temat: Genre Genre Genre Genre',\n",
       " '<extra_id_0> s. s. s.',\n",
       " '<extra_id_0>) )) )',\n",
       " '<extra_id_0> u.',\n",
       " '<extra_id_0> i s.',\n",
       " '<extra_id_0> – ogłoszono –',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0>) 17.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> )> > ) <extra_id_51> >',\n",
       " '<extra_id_0>.). <extra_id_49>. a. a. a. a. ',\n",
       " '<extra_id_0> nazwą.',\n",
       " '<extra_id_0> i waga to 172 <mask> gł.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> i uzyskały przyzwoite 97 <mask>',\n",
       " '<extra_id_0> - Niemcy - Polska',\n",
       " '<extra_id_0> o wyboru',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> s. s. s. s. s. s.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> opłatę obowiązującą opłatę obowiązującą;',\n",
       " '<extra_id_0>: 44 - 44',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> nauczyciela',\n",
       " '<extra_id_0>. ćw.',\n",
       " '<extra_id_0>.). <extra_id_49> i utrzymywane w tajemnicy i u',\n",
       " '<extra_id_0> służącym państwu polskim nie <extra_id_14> polski polityka',\n",
       " '<extra_id_0> - 0:0 - 0:0 - 0:0',\n",
       " '<extra_id_0> stanowiska Klubu. <extra_id_8> stanowiska Klubu.',\n",
       " '<extra_id_0> Informacji Turystycznej dnia 3 lipca był nieczynny -',\n",
       " '<extra_id_0> ul. ul. ul. ul. ul. ul.',\n",
       " '<extra_id_0> ma 8 oczka.ch <extra_id_26> ',\n",
       " '<extra_id_0> - nie więcej - nie mniej więcej',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> o. a ',\n",
       " '<extra_id_0> służących dzieci” ( <extra_id_10>)',\n",
       " '<extra_id_0> ś. 15).',\n",
       " '<extra_id_0> -.com',\n",
       " '<extra_id_0> o nie nie uchwalać o nie nie',\n",
       " '<extra_id_0> o kierunku kierunku kierunku kierunku kierunku ',\n",
       " '<extra_id_0> s. s. s. s.',\n",
       " '<extra_id_0> o wszystkim decydowaliśmy',\n",
       " '<extra_id_0> ul.',\n",
       " '<extra_id_0> - nauka języka polski',\n",
       " '<extra_id_0> ś. ś. ś.',\n",
       " '<extra_id_0> s. expand >',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> s. s. s.',\n",
       " '<extra_id_0> o l. l. l.',\n",
       " '<extra_id_0> rasy niebieskie rasy',\n",
       " '<extra_id_0> otworzy <mask> przewodnicząca Gdańska o stanowisku',\n",
       " '<extra_id_0> otworzy <mask> przewodnicząca Gdańska o stanowisku',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> - g. g. g. g.',\n",
       " '<extra_id_0> Zenit St Petersburg wygrał Zenit St Petersburg',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> u.',\n",
       " '<extra_id_0> ks. ks. ks. ks. ks. ks.',\n",
       " '<extra_id_0> - undefined >',\n",
       " '<extra_id_0> ks.',\n",
       " '<extra_id_0> i św.',\n",
       " '<extra_id_0> o. o.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> Kraków (<mask> 9).',\n",
       " '<extra_id_0> nazw pt. nazw nazw nazw nazw nazw nazw ',\n",
       " '<extra_id_0> kierunku kierunku kierunku kierunku kierunku kierunku',\n",
       " '<extra_id_0> kierunku kierunku kierunku kierunku kierunku kierunku',\n",
       " '<extra_id_0> służy bezpieczeństwa. <extra_id_8> bezpieczeństwa usługi.',\n",
       " '<extra_id_0> )',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> o części. <extra_id_8> części części części części.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> )',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> - bezpłatnie.',\n",
       " '<extra_id_0> o. o. o.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o o o o o o o o o',\n",
       " '<extra_id_0> o. o. o.',\n",
       " '<extra_id_0> i śniegu.',\n",
       " '<extra_id_0>)',\n",
       " '<extra_id_0> około godz. 11',\n",
       " '<extra_id_0> i rzeczywistości i',\n",
       " '<extra_id_0> - zobacz więcej o morderstwie. <extra_id_8> więcej o ',\n",
       " '<extra_id_0> o t. expand exports:',\n",
       " '<extra_id_0> polityka.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> wskazuje:',\n",
       " '<extra_id_0> o nazwisku. <extra_id_10> nazwisku  <extra_id_11>.',\n",
       " '<extra_id_0> ostrzegawczy -',\n",
       " '<extra_id_0> powiedział PAP.',\n",
       " '<extra_id_0> s. in',\n",
       " '<extra_id_0> - rozjuszenie, rozjuszenie,',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> - w. - w. -',\n",
       " '<extra_id_0> uczestników. <extra_id_10>  <extra_id_11>  <extra_id_11>  <extra_id_11>  <extra_id_11> )',\n",
       " '<extra_id_0> s.',\n",
       " '<extra_id_0>. o. o..ow',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> t. t. t. t. t. t.',\n",
       " '<extra_id_0> - tłumaczył.',\n",
       " '<extra_id_0> - zobacz więcej o prędkości -',\n",
       " '<extra_id_0> - nazwiska:',\n",
       " '<extra_id_0> o rosyjskiego o',\n",
       " '<extra_id_0> n. n. n.',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> u. in. <extra_id_9> u. in',\n",
       " '<extra_id_0> (s. 17,',\n",
       " '<extra_id_0> (s. 17,',\n",
       " '<extra_id_0>) s.',\n",
       " '<extra_id_0> -',\n",
       " \"<extra_id_0> '. <extra_id_10> '.\",\n",
       " '<extra_id_0> u. u.',\n",
       " '<extra_id_0> - zobacz więcej o Fox.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> g.',\n",
       " '<extra_id_0> stopniowo u służy stopniowo u służy stopni',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0>.wielkopolskie.<mask>',\n",
       " '<extra_id_0> u.',\n",
       " '<extra_id_0> - g.',\n",
       " '<extra_id_0> obywatela.cych o',\n",
       " '<extra_id_0> o.',\n",
       " \"<extra_id_0> '\",\n",
       " '<extra_id_0> - Niemcy -',\n",
       " '<extra_id_0> kultury.',\n",
       " '<extra_id_0> - undefined undefined undefined undefined undefined undefined undefined undefined',\n",
       " '<extra_id_0> - undefined undefined undefined undefined undefined undefined undefined undefined',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> sobota wieczorem wieczorem sobota wieczorem wieczorem',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>) )) )',\n",
       " '<extra_id_0> Kościoła –',\n",
       " \"<extra_id_0> wypadku zginął wypadek'malucha. <extra_id_10>\",\n",
       " '<extra_id_0> - nauka języka angielskiego',\n",
       " \"<extra_id_0> '.\",\n",
       " '<extra_id_0> o. in',\n",
       " '<extra_id_0> μg/m3)',\n",
       " '<extra_id_0> w.',\n",
       " '<extra_id_0> i',\n",
       " '<extra_id_0> i',\n",
       " '<extra_id_0> - Szlaku. <extra_id_10> - Szlaku.',\n",
       " '<extra_id_0> nazwiska <mask>',\n",
       " '<extra_id_0> - w.',\n",
       " '<extra_id_0> - a służącej służę',\n",
       " '<extra_id_0> expand abbreviation: <extra_id_8> ',\n",
       " '<extra_id_0> (s. 17)',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> i. i.',\n",
       " '<extra_id_0> służy usługi usługi usług',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0>)',\n",
       " '<extra_id_0> - - - - - -',\n",
       " '<extra_id_0> - - - - - -',\n",
       " '<extra_id_0> - n. 17',\n",
       " '<extra_id_0> (w. 17, 0-0)))))))))))))',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> s.',\n",
       " '<extra_id_0> - wszystkie mecze - części',\n",
       " '<extra_id_0> ciężarowych o ciężkim ciężkim ciężarowym',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> - Szturm.',\n",
       " '<extra_id_0> - wszystko oznacza angielskie',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> ) )',\n",
       " '<extra_id_0> stopnia stopnia stopnia stopnia stopnia stopnia',\n",
       " '<extra_id_0> stopnia stopnia stopnia stopnia stopnia stopnia',\n",
       " '<extra_id_0> stopnia stopnia stopnia stopnia stopnia stopnia',\n",
       " '<extra_id_0> sobota sobota sobota sobota sobota',\n",
       " '<extra_id_0> s.',\n",
       " '<extra_id_0> s.',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> i został wykonany na planie i została ukończony',\n",
       " '<extra_id_0> Kraków - Kraków',\n",
       " '<extra_id_0> Rzeszów -',\n",
       " '<extra_id_0> s.',\n",
       " '<extra_id_0> s. s.',\n",
       " '<extra_id_0> i nazwiska.',\n",
       " '<extra_id_0> Kraków – Kraków - Kraków',\n",
       " '<extra_id_0> s. in context:',\n",
       " '<extra_id_0> nauczyciela niemieckiego ',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> p.',\n",
       " '<extra_id_0> Średnia Średnia',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> PSL.',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> głosy. <extra_id_34> głosy głosy głosy głosy ',\n",
       " '<extra_id_0> s undefined.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> ul. ul.',\n",
       " '<extra_id_0> ul. ul. ul. ul. ul..',\n",
       " '<extra_id_0> służę. <extra_id_10> służę.',\n",
       " '<extra_id_0> - index:',\n",
       " '<extra_id_0> - index:',\n",
       " '<extra_id_0> - Wrocław -',\n",
       " '<extra_id_0> szkoda. <extra_id_8> szkoda.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> 1.0.1 służy pełnym pełnym pełnym pełnym ',\n",
       " '<extra_id_0> - n. n. n. n. n. ',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> otworzą multiplayer.com <extra_id_27> ',\n",
       " '<extra_id_0> u. in context:',\n",
       " '<extra_id_0> linii linii linii linii linii linii linii linii linii',\n",
       " '<extra_id_0> - sny. in context: sny. s',\n",
       " '<extra_id_0> o. o. o.',\n",
       " '<extra_id_0> - zagraniu',\n",
       " '<extra_id_0> n.',\n",
       " '<extra_id_0> covidowa.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> nazw prefix: prefix: prefix: prefix: prefix: ',\n",
       " '<extra_id_0> - u nazw >',\n",
       " '<extra_id_0> os. in context: lokalach os.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>)  <extra_id_1> służy -',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> -',\n",
       " '<extra_id_0> - polski język polski',\n",
       " '<extra_id_0> -',\n",
       " \"<extra_id_0> 'czeka żona prezydenta Gdańska Kaczyńskiego.cych wice\",\n",
       " '<extra_id_0> dzieci.',\n",
       " '<extra_id_0> - 129,5',\n",
       " '<extra_id_0> o o o o o o o o o',\n",
       " '<extra_id_0> l. l. l.',\n",
       " '<extra_id_0> o. o. o. o.',\n",
       " '<extra_id_0>. godz. in context:',\n",
       " '<extra_id_0>. ) –',\n",
       " '<extra_id_0> i.',\n",
       " '<extra_id_0> s. in',\n",
       " '<extra_id_0> awantur, do burd.',\n",
       " '<extra_id_0> awantur, do burd.',\n",
       " '<extra_id_0>?',\n",
       " '<extra_id_0> i oryginalność artykulu:',\n",
       " '<extra_id_0> -... <extra_id_8>.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o np.',\n",
       " '<extra_id_0> polityka i',\n",
       " '<extra_id_0> ). <extra_id_49> :.,.,. ',\n",
       " '<extra_id_0> czasowe i',\n",
       " '<extra_id_0> czasowe i',\n",
       " '<extra_id_0>) s.',\n",
       " '<extra_id_0>. o.',\n",
       " '<extra_id_0> o. o. o. o.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> wskazane jest wskazanie wskazań.',\n",
       " '<extra_id_0> o tytucie nazwiska o tytucie nazwiska nazw',\n",
       " '<extra_id_0> - cyfra s <extra_id_10> cyfra s g.',\n",
       " '<extra_id_0> sb sb sb sb sb',\n",
       " '<extra_id_0> spread spread spread spread spread spread spread spread',\n",
       " '<extra_id_0> s. s. s. s. s. s.',\n",
       " '<extra_id_0> – - - – – – – – – – – – – – – –',\n",
       " '<extra_id_0> n. n.',\n",
       " '<extra_id_0> wskazane.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> o. o. o.',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> - pływalnia pływalnia pływalnia pływalnia pływalnia ',\n",
       " '<extra_id_0> i nauka o rodzicach. i nauka',\n",
       " '<extra_id_0>.svg.svg',\n",
       " '<extra_id_0> kończy się na części końców drogi.',\n",
       " '<extra_id_0> s. s. s.',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> był bardzo reprezentatywny. <extra_id_8> ',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> s. s. s.',\n",
       " '<extra_id_0> o prezydenta B.icych',\n",
       " '<extra_id_0> o. o. o. o.',\n",
       " '<extra_id_0> nazwano. <extra_id_17> nazwano.',\n",
       " '<extra_id_0> o. o. o.',\n",
       " '<extra_id_0> o. o. o.',\n",
       " '<extra_id_0> zostało żon. in context:',\n",
       " '<extra_id_0> polityka',\n",
       " '<extra_id_0> ćwiczy ćwiczy ćwiczy ćwiczy ć',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> wskazał protest.',\n",
       " '<extra_id_0>) (',\n",
       " '<extra_id_0> i',\n",
       " '<extra_id_0> i',\n",
       " '<extra_id_0> g. g. g. g. g. g.',\n",
       " '<extra_id_0> a margin:',\n",
       " '<extra_id_0> - a <extra_id_14> a.',\n",
       " '<extra_id_0>: m •',\n",
       " '<extra_id_0>:',\n",
       " '<extra_id_0> ). <extra_id_49> i jego rodzina. Książka. Książk',\n",
       " '<extra_id_0> polityki',\n",
       " '<extra_id_0> - n. n. n. n.',\n",
       " '<extra_id_0> opozycji nadal nadal nadal nadal nadal nadal nadal',\n",
       " '<extra_id_0> opozycji nadal nadal nadal nadal nadal nadal nadal',\n",
       " '<extra_id_0> znajduje się znajdujący się :',\n",
       " '<extra_id_0> - miasto -',\n",
       " '<extra_id_0> - g.',\n",
       " '<extra_id_0> francuskiego) francuskiego) specjalistycznym )',\n",
       " '<extra_id_0> emerytur emerytur',\n",
       " '<extra_id_0> o nazwiska <mask>',\n",
       " '<extra_id_0> ) ) ))',\n",
       " '<extra_id_0> s. s. s. s.',\n",
       " '<extra_id_0> s. s. s. s.',\n",
       " '<extra_id_0>; godz. 18.00 skrzymienia. Więcej',\n",
       " '<extra_id_0> kapitana i',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> oznacza krótki o śniegu. <extra_id_8> ',\n",
       " '<extra_id_0> i s <extra_id_8> i',\n",
       " '<extra_id_0> s. s. s. s. s. s.',\n",
       " '<extra_id_0>: ) > > > > > > > > > <',\n",
       " '<extra_id_0> - r. r. - ',\n",
       " '<extra_id_0> o szczepienia się była wyższa.',\n",
       " '<extra_id_0> g.',\n",
       " '<extra_id_0> s. in context.',\n",
       " '<extra_id_0>.)',\n",
       " '<extra_id_0> a a',\n",
       " '<extra_id_0> o obowiązku prawo o obowiązku o obowiązku ',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0> - s.',\n",
       " '<extra_id_0>. ). <extra_id_49> ę. ć. ć. ć. ',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0>. ).',\n",
       " '<extra_id_0> około. <extra_id_10> około.',\n",
       " '<extra_id_0> o u u u u u u u u',\n",
       " '<extra_id_0> - s.',\n",
       " '<extra_id_0> - p. s.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> -.u <extra_id_26> /',\n",
       " '<extra_id_0> o. in context: o.',\n",
       " '<extra_id_0> o. o. o. o. o. o.',\n",
       " '<extra_id_0>?',\n",
       " '<extra_id_0> - zobacz szczegóły -',\n",
       " '<extra_id_0> - zobacz szczegóły -',\n",
       " '<extra_id_0> s. 12',\n",
       " '<extra_id_0> s. 12',\n",
       " '<extra_id_0> - a artykule -',\n",
       " '<extra_id_0> nazwiska nazwiska nazwiska nazwiska nazwiska nazwiska',\n",
       " '<extra_id_0> - miasto',\n",
       " '<extra_id_0> o.',\n",
       " '<extra_id_0>.',\n",
       " '<extra_id_0> obywatelskiego.',\n",
       " '<extra_id_0> o. o.',\n",
       " '<extra_id_0> czasownika.',\n",
       " '<extra_id_0>, s.',\n",
       " '<extra_id_0> s. 18',\n",
       " '<extra_id_0> miasto miasto miasto miasto miasto',\n",
       " '<extra_id_0> -.',\n",
       " '<extra_id_0> był piwowarem. <extra_id_14> częścia.',\n",
       " '<extra_id_0> s.',\n",
       " '<extra_id_0> pożarna pożarni pożarni pożarni pożarni pożarni',\n",
       " '<extra_id_0> - g. g. g. g.',\n",
       " '<extra_id_0> nazw nazw nazw nazw nazw nazw nazw nazw nazw',\n",
       " '<extra_id_0> o. o.',\n",
       " '<extra_id_0> o.',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gil.',\n",
       " 'wewnętrzny',\n",
       " 'sobota',\n",
       " 'metrów',\n",
       " 'age.',\n",
       " 'godzina',\n",
       " 'byłego',\n",
       " 'ojciec',\n",
       " 'F. spółka',\n",
       " 'metrów',\n",
       " 'godzina',\n",
       " 'piątek telefon',\n",
       " 'ojciec',\n",
       " 'godzina',\n",
       " 'WiR.',\n",
       " 'środa',\n",
       " 'sobota',\n",
       " 'punktów',\n",
       " 'wiersz; werset',\n",
       " 'cesarsko-królewskiej',\n",
       " 'Nic. Zero.',\n",
       " 'ojciec',\n",
       " 'asysta',\n",
       " 'byłego',\n",
       " 'jeziora',\n",
       " 'pani',\n",
       " 'litr',\n",
       " 'metrów',\n",
       " 'językiem',\n",
       " 'województwie',\n",
       " 'gać.',\n",
       " 'ulica',\n",
       " 'niedziela',\n",
       " 'metra',\n",
       " 'imienia biskupa',\n",
       " 'pracy',\n",
       " 'pan',\n",
       " 'pani',\n",
       " 'pana',\n",
       " 'wieku',\n",
       " 'bok.',\n",
       " 'Kapitan',\n",
       " 'bo.',\n",
       " 'sobota',\n",
       " 'pani',\n",
       " 'sobota',\n",
       " 'punktów',\n",
       " 'godzina',\n",
       " 'log.',\n",
       " 'mieście',\n",
       " 'ojca',\n",
       " 'matka',\n",
       " 'wieku',\n",
       " 'sobota',\n",
       " 'bramka',\n",
       " 'była',\n",
       " 'Cow.',\n",
       " 'stronach',\n",
       " 'miasta',\n",
       " 'pic.',\n",
       " 'miasto',\n",
       " 'wieczny',\n",
       " 'niedziela',\n",
       " 'dogrywka',\n",
       " 'pan',\n",
       " 'wieku',\n",
       " 'ojciec',\n",
       " 'a.',\n",
       " 'koń.',\n",
       " 'metrów',\n",
       " 'były',\n",
       " 'ojciec',\n",
       " 'imienia',\n",
       " 'godzinę',\n",
       " 'baryłkę',\n",
       " 'były',\n",
       " 'były',\n",
       " 'ojców',\n",
       " 'grupie C.',\n",
       " 'sobota',\n",
       " 'waga',\n",
       " 'łez.',\n",
       " 'firmą',\n",
       " 'dziennie',\n",
       " 'sekundy',\n",
       " 'sobota',\n",
       " 'niedziela',\n",
       " 'reżyseria',\n",
       " 'tonę',\n",
       " 'tonę',\n",
       " 'cdx.pl.',\n",
       " 'dawniej',\n",
       " 'pan',\n",
       " 'wewnętrzny',\n",
       " 'generała',\n",
       " 'pani',\n",
       " 'sobota',\n",
       " 'ojca',\n",
       " 'roku',\n",
       " 'państwo',\n",
       " 'imienia',\n",
       " 'wył.',\n",
       " 'byłego',\n",
       " 'przez',\n",
       " 'ojciec',\n",
       " 'Arcybiskupa',\n",
       " 'c.',\n",
       " 'sobota',\n",
       " 'miesiąca',\n",
       " 'baryłkę',\n",
       " 'ma',\n",
       " 'pana',\n",
       " 'metrów',\n",
       " 'godzina',\n",
       " 'baryłkę',\n",
       " 'była',\n",
       " 'ryż.',\n",
       " 'wieku przed naszą erą',\n",
       " 'godzinę',\n",
       " 'paragraf',\n",
       " 'tony',\n",
       " 'pum.',\n",
       " 'wieku',\n",
       " 'metra',\n",
       " 'ojca',\n",
       " 'd.',\n",
       " 'byłych',\n",
       " 'd.',\n",
       " 'godzinę',\n",
       " 'godzina',\n",
       " 'koło',\n",
       " 'ojciec',\n",
       " 'pokój',\n",
       " 'metrach',\n",
       " 'punkt',\n",
       " 'ojciec',\n",
       " 'ać.',\n",
       " 'godzinę',\n",
       " 'raz.',\n",
       " 'b.',\n",
       " 'ojca',\n",
       " 'południowej',\n",
       " 'starsza aspirantka',\n",
       " 'niedziela',\n",
       " 'metra',\n",
       " 'sobota',\n",
       " 'niedziela',\n",
       " 'Wam.',\n",
       " 'sobota',\n",
       " 'Lee.',\n",
       " 'dań.',\n",
       " 'Biskup',\n",
       " 'niedziela',\n",
       " 'w sprawie doktora',\n",
       " 'byłego',\n",
       " 'sam.',\n",
       " 'z.',\n",
       " 'ojciec',\n",
       " 'przez',\n",
       " 'Ski.',\n",
       " 'Can.',\n",
       " 'kaprala pilota',\n",
       " 'metry',\n",
       " 'rośnie',\n",
       " 'niedziela',\n",
       " 'sobota',\n",
       " 'godzinę',\n",
       " 'pana',\n",
       " 'ojca',\n",
       " 'tonę',\n",
       " 'tonę',\n",
       " 'werset',\n",
       " 'pages',\n",
       " 'metra',\n",
       " 'wewnętrzny',\n",
       " 'punktu',\n",
       " 'numerem ewidencyjnym',\n",
       " 'dziennie',\n",
       " 'ulicy',\n",
       " 'telewizji',\n",
       " 'ojciec',\n",
       " 'sił.',\n",
       " 'cka.',\n",
       " 'reżyseria',\n",
       " 'panu',\n",
       " 'tysięcy łosi.',\n",
       " 'sobota',\n",
       " 'środa',\n",
       " 'byłej',\n",
       " 'Kodeksu karnego',\n",
       " 'c.',\n",
       " 'lis.',\n",
       " 'Pin.',\n",
       " 'wieku',\n",
       " 'godzina',\n",
       " 'godzina',\n",
       " 'roku',\n",
       " 'błogosławiony',\n",
       " 'niedziela',\n",
       " 'sobota',\n",
       " 'ojciec',\n",
       " 'Ram.',\n",
       " 'dziennie',\n",
       " 'sędzia',\n",
       " 'były',\n",
       " 'metra',\n",
       " 'były',\n",
       " 'panią',\n",
       " 'uzgodnionego',\n",
       " 'Cz.',\n",
       " 'jeziorem',\n",
       " 'strona',\n",
       " 'tył.',\n",
       " 'pan',\n",
       " 'siostrą',\n",
       " 'Men.',\n",
       " 'run.',\n",
       " 'godzinę',\n",
       " 'byłej',\n",
       " 'kodeksu karnego',\n",
       " 'imienia J.',\n",
       " 'bieżącego roku ojciec',\n",
       " 'imienia',\n",
       " 'panu',\n",
       " 'godzinę',\n",
       " 'godzinę',\n",
       " 'siostrę',\n",
       " 'przez',\n",
       " 'godzinę',\n",
       " 'wiek',\n",
       " 'pana',\n",
       " 'x.',\n",
       " 'księdza prałata',\n",
       " 'meczów',\n",
       " 'jak wyżej',\n",
       " 'dawnych',\n",
       " 'imienia',\n",
       " 'niedziela',\n",
       " 'miejscowości',\n",
       " 'karne',\n",
       " 'sekundy',\n",
       " 'pana',\n",
       " 'ojciec',\n",
       " 'nauk humanistycznych',\n",
       " 'metra',\n",
       " 'litr',\n",
       " 'Wa.',\n",
       " 'b.',\n",
       " 'kas.',\n",
       " 'lekarz stomatolog',\n",
       " 'wy.',\n",
       " 'bieżących',\n",
       " 'cum.',\n",
       " 'gaz.',\n",
       " 'metrów',\n",
       " 'metry',\n",
       " 'V. Liga.',\n",
       " 'lol.',\n",
       " 'nad poziomem morza',\n",
       " 'dawniej',\n",
       " 'budżet',\n",
       " 'godzinę',\n",
       " 'tysięcy kilometrów',\n",
       " 'kum.',\n",
       " 'werset',\n",
       " 'świętą Annę.',\n",
       " 'sobota',\n",
       " 'godzinę',\n",
       " 'niedziela',\n",
       " 'nad',\n",
       " 'metrów',\n",
       " 'metrów',\n",
       " 'sobota',\n",
       " 'rotmistrza',\n",
       " 'panią',\n",
       " 'godzinę',\n",
       " 'tysiąca kilometrów',\n",
       " 'pan',\n",
       " 'sobota',\n",
       " 'pani',\n",
       " 'ojca',\n",
       " 'niedziela',\n",
       " 'Załącznika',\n",
       " 'sęp.',\n",
       " 'godzinę',\n",
       " 'godzinę',\n",
       " 'ojca',\n",
       " 'wieku',\n",
       " 'bieżącego roku około godziny',\n",
       " 'porównaj na przykład uchwałę',\n",
       " 'doktora',\n",
       " 'siostra',\n",
       " 'na przykład świętego',\n",
       " 'część',\n",
       " 'byłych',\n",
       " 'środa',\n",
       " 'godzina',\n",
       " 'niedziela',\n",
       " 'wieku',\n",
       " 'język',\n",
       " 'godzina',\n",
       " 'lat.',\n",
       " 'sekundę',\n",
       " 'karny',\n",
       " 'dawna',\n",
       " 'koło',\n",
       " 'byłego',\n",
       " 'wieku',\n",
       " 'kodeks karny',\n",
       " 'sobota',\n",
       " 'Ahr.',\n",
       " 'byłego',\n",
       " 'niedziela',\n",
       " 'byłemu',\n",
       " 'niedziela',\n",
       " 'niedziela',\n",
       " 'metrów',\n",
       " 'wiecznej',\n",
       " 'jeziora',\n",
       " 'pana',\n",
       " 'godzinę',\n",
       " 'tonę',\n",
       " 'litra',\n",
       " 'niedziela',\n",
       " 'mus.',\n",
       " 'ojciec',\n",
       " 'potocznie',\n",
       " 'niedziela',\n",
       " 'dur.',\n",
       " 'pan',\n",
       " 'syna',\n",
       " 'ojca',\n",
       " 'ojca',\n",
       " 'pił.',\n",
       " 'ojca',\n",
       " 'sobota',\n",
       " 'w.',\n",
       " 'byłych',\n",
       " 'rok',\n",
       " 'godziny',\n",
       " 'ojciec',\n",
       " 'ojca',\n",
       " 'ojciec',\n",
       " 'zła.',\n",
       " 'en.',\n",
       " 'ojcu',\n",
       " 'tysiąc kilogramów',\n",
       " 'rysunek',\n",
       " 'wieku',\n",
       " 'metry',\n",
       " 'metry',\n",
       " 'sto.',\n",
       " 'według',\n",
       " 'strona',\n",
       " 'niedziela',\n",
       " 'ulica',\n",
       " 'niedziela',\n",
       " 'niedziela',\n",
       " 'Gigaherców',\n",
       " 'niedziela',\n",
       " 'paragraf',\n",
       " 'godzinę',\n",
       " 'oddział',\n",
       " 'metry',\n",
       " 'pani',\n",
       " 'niedziela',\n",
       " 'odcinek',\n",
       " 'środa',\n",
       " 'środa',\n",
       " 'wagi',\n",
       " 'tub.',\n",
       " 'ą.',\n",
       " 'byłego',\n",
       " 'gramów',\n",
       " 'były',\n",
       " 'was.',\n",
       " 'dziennie',\n",
       " 'dziennie',\n",
       " 'były',\n",
       " 'ojca',\n",
       " 'godzina',\n",
       " 'godzina',\n",
       " 'bieżącego',\n",
       " 'ojciec',\n",
       " 'metrów',\n",
       " 'powiat',\n",
       " 'ana.',\n",
       " 'panią',\n",
       " 'godzinę',\n",
       " 'godzinę',\n",
       " 'punkt',\n",
       " 'ojca',\n",
       " 'sekund',\n",
       " 'ego.',\n",
       " 'ojca',\n",
       " 'to jest około',\n",
       " 'Ryu.',\n",
       " 'men.gov.pl.',\n",
       " 'pan',\n",
       " 'wieku',\n",
       " 'sobota',\n",
       " 'pana',\n",
       " 'metrów',\n",
       " 'godzina',\n",
       " 'strona',\n",
       " 'ksiądz doktor',\n",
       " 'z.',\n",
       " 'wieku',\n",
       " 'sekundę',\n",
       " 'pół.',\n",
       " 'metra',\n",
       " 'niedziela',\n",
       " 'metry',\n",
       " 'siostry',\n",
       " 'rei.',\n",
       " 'rondo',\n",
       " 'zewnętrznych',\n",
       " 'ojca',\n",
       " 'niedziela',\n",
       " 'panu',\n",
       " 'imienia świętego',\n",
       " 'to jest',\n",
       " 'była',\n",
       " 'panu',\n",
       " 'nad',\n",
       " 'procentowego',\n",
       " 'metra',\n",
       " 'rei.',\n",
       " 'metra',\n",
       " 'wieku',\n",
       " 'siostra',\n",
       " 'lał.',\n",
       " 'f.',\n",
       " 'USA. między innymi',\n",
       " 'sobota',\n",
       " 'mym.',\n",
       " 'Goi.',\n",
       " 'mac.',\n",
       " 'ubiegłego roku',\n",
       " 'niedziela',\n",
       " 'raz.',\n",
       " 'tonę',\n",
       " 'ojciec',\n",
       " 'dziennie',\n",
       " 'dziennie',\n",
       " 'z ograniczoną odpowiedzialnością',\n",
       " 'panią',\n",
       " 'dni. T.',\n",
       " 'godzina',\n",
       " 'miasto',\n",
       " 'sos.',\n",
       " 'niedziela',\n",
       " 'ceł.',\n",
       " 'bzu.',\n",
       " 'w.',\n",
       " 'how.',\n",
       " 'godzinę',\n",
       " 'ojciec',\n",
       " 'ojciec',\n",
       " 'godzinę',\n",
       " 'strona',\n",
       " 'strona',\n",
       " 'sam.',\n",
       " 'godzina',\n",
       " 'byłym',\n",
       " 'niedziela',\n",
       " 'metrów',\n",
       " 'byłego',\n",
       " 'For.',\n",
       " 'spa.',\n",
       " 'habilitowany inżynier',\n",
       " 'rad.',\n",
       " 'boa.',\n",
       " 'ojciec',\n",
       " 'UE. Nie.',\n",
       " 'były',\n",
       " 'sobota',\n",
       " 'sobota',\n",
       " 'owe.',\n",
       " 'imienia F.',\n",
       " 'godzinę',\n",
       " 'roku między innymi',\n",
       " 'sobota',\n",
       " 'ojca',\n",
       " 'chu.',\n",
       " 'ojca',\n",
       " 'niedziela',\n",
       " 'sobota',\n",
       " 'ton',\n",
       " 'była',\n",
       " 'c.',\n",
       " 'pełny',\n",
       " 'sekund',\n",
       " 'byłego',\n",
       " 'miejsce',\n",
       " 'gramów',\n",
       " 'sobota',\n",
       " 'sobota',\n",
       " 'er.',\n",
       " 'ojca',\n",
       " 'u.',\n",
       " 'imienia',\n",
       " 'była',\n",
       " 'Nic. Zero.',\n",
       " 'w sprawie',\n",
       " 'dawniej',\n",
       " 'Wam.',\n",
       " 'Lip.',\n",
       " 'dawniej',\n",
       " 'evo.',\n",
       " 'przed Chrystusem',\n",
       " 'lekarz dentysta',\n",
       " 'ojciec',\n",
       " 'abc.',\n",
       " 'godzinę',\n",
       " 'związku',\n",
       " 'powiat',\n",
       " 'sędziego',\n",
       " 'rób.',\n",
       " 'ojciec',\n",
       " 'na przykład lisy.',\n",
       " 'kodeksu',\n",
       " 'na przykład lisy.',\n",
       " 'ł.',\n",
       " 'rondo',\n",
       " 'matka',\n",
       " 'ru.',\n",
       " 'metrów',\n",
       " 'metry',\n",
       " 'volume',\n",
       " 'dawnym',\n",
       " 'metrze',\n",
       " 'były',\n",
       " 'sędzia',\n",
       " 'sobota',\n",
       " 'i tak dalej',\n",
       " 'dupa',\n",
       " 'gramów',\n",
       " 'na przykład kardynała',\n",
       " 'tor.',\n",
       " 'godzina',\n",
       " 'godzinę',\n",
       " 'panu',\n",
       " 'litra',\n",
       " 'byłej żony.',\n",
       " 'byłego',\n",
       " 'ojciec',\n",
       " 'godzinę',\n",
       " 'świętej pamięci admirała',\n",
       " 'hej.',\n",
       " 'ojciec',\n",
       " 'młodszego chorążego sztabowego',\n",
       " 'dziennie',\n",
       " 'godzina',\n",
       " 'metra kwadratowego powierzchni',\n",
       " 'Oli.',\n",
       " 'to jest minimum',\n",
       " 'ojcze',\n",
       " 'dawną',\n",
       " 'wiecznej',\n",
       " 'godzinę',\n",
       " 'godzinę',\n",
       " 'serii',\n",
       " 'godzinę',\n",
       " 'ton',\n",
       " 'godzina',\n",
       " 'między innymi doktora',\n",
       " 'rozdział',\n",
       " 'godzina',\n",
       " 'ojciec',\n",
       " 'gry.',\n",
       " 'punkt',\n",
       " 'hak.',\n",
       " 'rzuty karne',\n",
       " 'kilometrów',\n",
       " 'owi.',\n",
       " 'byłą',\n",
       " 'punkt; paragraf',\n",
       " 'z.',\n",
       " 'ojca',\n",
       " 'tonę',\n",
       " 'sobota',\n",
       " 'ryż.',\n",
       " 'godzinę',\n",
       " 'ViP.',\n",
       " 'godzinę',\n",
       " 'ojciec',\n",
       " 'godzinę',\n",
       " 'punkty',\n",
       " 'godzina',\n",
       " 'pan',\n",
       " 'pani',\n",
       " 'Joj.',\n",
       " 'wieku',\n",
       " 'tonę',\n",
       " 'bieżącego miesiąca',\n",
       " 'a.',\n",
       " 'versus',\n",
       " 'sekundę',\n",
       " 'godzina',\n",
       " 'niedziela',\n",
       " 'wieku',\n",
       " 'c.',\n",
       " 'ojciec',\n",
       " 'letniemu',\n",
       " 'godzinę',\n",
       " 'siostrą',\n",
       " 'ojców',\n",
       " 'nóg.',\n",
       " 'pana',\n",
       " 'godzinę',\n",
       " 'godzinę',\n",
       " 'litr',\n",
       " 'pages',\n",
       " 'rondo',\n",
       " 'metra',\n",
       " 'świętej pamięci arcybiskupa',\n",
       " 'Rat.',\n",
       " 'werset',\n",
       " 'pani',\n",
       " 'sobota',\n",
       " 'x.',\n",
       " 'to jest około godziny',\n",
       " 'świętą Annę.',\n",
       " 'powiecie',\n",
       " 'godzinę',\n",
       " 'Pełniący obowiązki',\n",
       " 'godzinę',\n",
       " 'ojciec',\n",
       " 'ojciec',\n",
       " 'punktu',\n",
       " 'punktów',\n",
       " 'placu',\n",
       " 'zobacz na przykład',\n",
       " 'liczba',\n",
       " 'sobota',\n",
       " 'lata',\n",
       " 'godzinę',\n",
       " 'siostrą',\n",
       " 'b.',\n",
       " 'ojciec',\n",
       " 'mel.',\n",
       " 'świętej pamięci starszego',\n",
       " 'byłych',\n",
       " 'fi.',\n",
       " 'syn',\n",
       " 'sobota',\n",
       " 'ulicy',\n",
       " 'siostra',\n",
       " 'mieście',\n",
       " 'pana',\n",
       " 'ojciec',\n",
       " 'sobota',\n",
       " 'na przykład około',\n",
       " 'ach.',\n",
       " 'dawniej',\n",
       " 'post scriptum',\n",
       " 'gramy',\n",
       " 'ojciec',\n",
       " 'metrów',\n",
       " 'Bug.',\n",
       " 'byłych',\n",
       " 'ojca',\n",
       " 'sobota',\n",
       " 'uli.',\n",
       " 'b.',\n",
       " 'karne',\n",
       " 'metrach',\n",
       " 'wewnętrzny',\n",
       " 'nią.',\n",
       " 'who.',\n",
       " 'to.',\n",
       " 'sędzia; sędziował',\n",
       " 'a.',\n",
       " 'państwo',\n",
       " 'to jest ulicą',\n",
       " 'megapikseli',\n",
       " 'godzinę',\n",
       " 'wewnętrzny',\n",
       " 'wewnętrzny',\n",
       " 'życia',\n",
       " 'strona',\n",
       " 'środa',\n",
       " 'Junior',\n",
       " 'ima.',\n",
       " 'godzinę',\n",
       " 'sobota',\n",
       " 'łuk.',\n",
       " 'pani',\n",
       " 'pod wezwaniem świętego',\n",
       " 'święty',\n",
       " 'sekundy',\n",
       " 'karny',\n",
       " 'strona',\n",
       " 'lata',\n",
       " 'zamieszkanie',\n",
       " 'była',\n",
       " 'była',\n",
       " 'syna',\n",
       " 'godzina',\n",
       " 'grupy C.',\n",
       " 'metra',\n",
       " 'ulica',\n",
       " 'bieżącego roku ksiądz',\n",
       " 'godzinę',\n",
       " 'ojca',\n",
       " 'między innymi świętą',\n",
       " 'pana',\n",
       " 'godzina',\n",
       " 'sobota',\n",
       " 'pod tytułem',\n",
       " 'godzinę',\n",
       " 'godzinę',\n",
       " 'f.',\n",
       " 'boisko',\n",
       " 'dawna',\n",
       " 'godzinę',\n",
       " 'Lew.',\n",
       " 'lot.',\n",
       " 'bardzo dobry',\n",
       " 'poniedziałek godzina',\n",
       " 'ojcu',\n",
       " 'c.',\n",
       " 'punktu; paragrafu',\n",
       " 'ojca',\n",
       " 'metrów',\n",
       " 'niedziela',\n",
       " 'panem',\n",
       " 'panią',\n",
       " 'bardzo',\n",
       " 'tonę',\n",
       " 'wieku',\n",
       " 'metra',\n",
       " 'ksiądz',\n",
       " 'Id.',\n",
       " 'ran.',\n",
       " 'byłego',\n",
       " 'siostra',\n",
       " 'mąt.',\n",
       " 'niedziela',\n",
       " 'wewnętrzny',\n",
       " 'Pur.',\n",
       " 'siostra',\n",
       " 'ojciec',\n",
       " 'były',\n",
       " 'tekst',\n",
       " 'mak.',\n",
       " 'godzinę',\n",
       " 'xx.',\n",
       " 'dziennie',\n",
       " 'nauczyciele',\n",
       " 'sobota',\n",
       " 'państwa',\n",
       " 'u.',\n",
       " 'niedziela',\n",
       " 'niedziela',\n",
       " 'sobota',\n",
       " 'godzina',\n",
       " 'wieku',\n",
       " 'u.',\n",
       " 'Fox.',\n",
       " 'węźle',\n",
       " 'godzina',\n",
       " 'strony',\n",
       " 'ojca',\n",
       " 'pl.',\n",
       " 'ulica',\n",
       " 'godzina',\n",
       " 'byłego',\n",
       " 'ojcem',\n",
       " 'metrów',\n",
       " 'godzinę',\n",
       " 'pana',\n",
       " 'baryłkę',\n",
       " 'baryłkę',\n",
       " 'pan',\n",
       " 'metry',\n",
       " 'miejsce',\n",
       " 'środa',\n",
       " 'aleja',\n",
       " 'p.',\n",
       " 'piętro',\n",
       " 'godzinę',\n",
       " 'ojciec',\n",
       " 'mikrogramów',\n",
       " 'węzeł',\n",
       " 'godzinę',\n",
       " 'godzinę',\n",
       " 'półwyspu',\n",
       " 'Aj.',\n",
       " 'wewnętrzny',\n",
       " 'byłym',\n",
       " 'inżynier',\n",
       " 'sobota',\n",
       " 'godzinie',\n",
       " 'i.',\n",
       " 'rok.',\n",
       " 'pan, premier',\n",
       " 'tvn.',\n",
       " 'środa',\n",
       " 'miejscowość',\n",
       " 'miejscowość',\n",
       " 'niedziela',\n",
       " 'wtorek',\n",
       " 'ojciec',\n",
       " 'serii',\n",
       " 'środa',\n",
       " 'ton',\n",
       " 'o.',\n",
       " 'Mur.',\n",
       " 'El.',\n",
       " 'ojciec',\n",
       " 'nauk',\n",
       " 'godzinę',\n",
       " 'godzinę',\n",
       " 'godzinę',\n",
       " 'dnia',\n",
       " 'sobota',\n",
       " 'sobota',\n",
       " 'syna',\n",
       " 'ona.',\n",
       " 'metra',\n",
       " 'dawniej',\n",
       " 'sobota',\n",
       " 'siostra',\n",
       " 'sobota',\n",
       " 'wieku',\n",
       " 'środa',\n",
       " 'sobota',\n",
       " 'języka',\n",
       " 'ojciec',\n",
       " 'panem',\n",
       " 'godzinę',\n",
       " 'off.',\n",
       " 'dawna',\n",
       " 'ojciec',\n",
       " 'bbo.',\n",
       " 'lep.',\n",
       " 'metra',\n",
       " 'ulicy',\n",
       " 'pani',\n",
       " 'jęk.',\n",
       " 'metra',\n",
       " 'metra',\n",
       " 'imienia Kapitana',\n",
       " 'pomoc',\n",
       " 'mis.',\n",
       " 'rozdział',\n",
       " 'pól.',\n",
       " 'niedziela',\n",
       " 'piłka',\n",
       " 'strona',\n",
       " 'Day.',\n",
       " 'ulicy',\n",
       " 'Gór.',\n",
       " 'sny.',\n",
       " 'ojca',\n",
       " 'godzina',\n",
       " 'niedziela',\n",
       " 'Tak zwana',\n",
       " 'eko.',\n",
       " 'to jest',\n",
       " 'mieszkania',\n",
       " 'osoba',\n",
       " 'godzina',\n",
       " 'woń.',\n",
       " 'osiedle',\n",
       " 'pani',\n",
       " 'pan',\n",
       " 'metrów',\n",
       " 'była',\n",
       " 'godziny',\n",
       " 'metra',\n",
       " 'panem',\n",
       " 'litr',\n",
       " 'ojciec',\n",
       " 'Około godziny',\n",
       " 'bić.',\n",
       " 'przez',\n",
       " 'siostra',\n",
       " 'byłego',\n",
       " 'byłego',\n",
       " 'były',\n",
       " 'klasa',\n",
       " 'miejscowościach',\n",
       " 'ojciec',\n",
       " 'na przykład około',\n",
       " 'były',\n",
       " 'kwartale',\n",
       " 'metrów',\n",
       " 'metrów',\n",
       " 'sobota',\n",
       " 'ojca',\n",
       " 'ojciec',\n",
       " 'jezioro',\n",
       " 'Między innymi',\n",
       " 'Mag.',\n",
       " 'godzina',\n",
       " 'sobota godzina',\n",
       " 'baryłkę',\n",
       " 'siostra',\n",
       " 'masy',\n",
       " 'niedziela',\n",
       " 'panie',\n",
       " 'ojciec',\n",
       " 'ojca',\n",
       " 'ojca',\n",
       " 'sobota',\n",
       " 'dar.',\n",
       " 'gif.',\n",
       " 'metrów',\n",
       " 'w sprawie',\n",
       " 'ojciec',\n",
       " 'ojciec',\n",
       " 'panem',\n",
       " 'metrów nad poziomem morza',\n",
       " 'sobota',\n",
       " 'państwo',\n",
       " 'ojciec',\n",
       " 'nią.',\n",
       " 'ojca',\n",
       " 'ojciec',\n",
       " 'żon.',\n",
       " 'panu',\n",
       " 'ą.',\n",
       " 'imienia',\n",
       " 'pana',\n",
       " 'sobota',\n",
       " 'dawna',\n",
       " 'dawna',\n",
       " 'godzina',\n",
       " 'połowie',\n",
       " 'byli',\n",
       " 'Wysokość',\n",
       " 'bramka',\n",
       " 'Pra.',\n",
       " 'siostra',\n",
       " 'niedziela',\n",
       " 'godzinę',\n",
       " 'godzinę',\n",
       " 'litrów',\n",
       " 'budżet',\n",
       " 'godzina',\n",
       " 'językiem',\n",
       " 'w sprawie',\n",
       " 'dat.',\n",
       " 'tea.',\n",
       " 'sobota',\n",
       " 'sobota',\n",
       " 'reżyseria',\n",
       " 'żeglugi wielkiej',\n",
       " 'dobre',\n",
       " 'minimum około',\n",
       " 'j.',\n",
       " 'strony',\n",
       " 'milimetrów Temperatura maksymalna',\n",
       " 'ronda',\n",
       " 'doktor',\n",
       " 'godzina',\n",
       " 'strony',\n",
       " 'liczba mnoga',\n",
       " 'bez',\n",
       " 'ustęp',\n",
       " 'ojciec',\n",
       " 'sekundy',\n",
       " 'ę.',\n",
       " 'jak. między innymi',\n",
       " 'nie. Na przykład',\n",
       " 'tonę',\n",
       " 'lud.',\n",
       " 'pani',\n",
       " 'pan',\n",
       " 'pod wezwaniem',\n",
       " 'godzinę',\n",
       " 'ojca',\n",
       " 'ojciec',\n",
       " 'Hertzach',\n",
       " 'godzinę',\n",
       " 'godzinę',\n",
       " 'niedziela',\n",
       " 'niedziela',\n",
       " 'koło',\n",
       " 'pan',\n",
       " 'kas.',\n",
       " 'pan',\n",
       " 'siostra',\n",
       " 'bbo.',\n",
       " 'dawnego',\n",
       " 'wiekiem',\n",
       " 'strona',\n",
       " 'sobota',\n",
       " 'metrów',\n",
       " 'jeziora',\n",
       " 'łaciński',\n",
       " 'matka',\n",
       " 'powiat',\n",
       " 'godzina',\n",
       " 'wieku',\n",
       " 'w.',\n",
       " 'ojciec',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Abbr_env-FC8IvZ7o",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
